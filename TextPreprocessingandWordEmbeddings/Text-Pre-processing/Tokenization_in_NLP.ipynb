{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Word Tokenization </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Founded',\n",
       " 'in',\n",
       " '2002,',\n",
       " 'SpaceX’s',\n",
       " 'mission',\n",
       " 'is',\n",
       " 'to',\n",
       " 'enable',\n",
       " 'humans',\n",
       " 'to',\n",
       " 'become',\n",
       " 'a',\n",
       " 'spacefaring',\n",
       " 'civilization',\n",
       " 'and',\n",
       " 'a',\n",
       " 'multi-planet',\n",
       " 'species',\n",
       " 'by',\n",
       " 'building',\n",
       " 'a',\n",
       " 'self-sustaining',\n",
       " 'city',\n",
       " 'on',\n",
       " 'Mars.',\n",
       " 'In',\n",
       " '2008,',\n",
       " 'SpaceX’s',\n",
       " 'Falcon',\n",
       " '1',\n",
       " 'became',\n",
       " 'the',\n",
       " 'first',\n",
       " 'privately',\n",
       " 'developed',\n",
       " 'liquid-fuel',\n",
       " 'launch',\n",
       " 'vehicle',\n",
       " 'to',\n",
       " 'orbit',\n",
       " 'the',\n",
       " 'Earth.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Work tokenization\n",
    "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
    "species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
    "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
    "# Splits at space \n",
    "text.split() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sentence Tokenization</h1>\n",
    "\n",
    "<h5>This is similar to work tokenization. Here, we study the structure of sentences in the analysis. A sentence usually ends with a full stop (.), so we can use \".\" as a separator to break the string:</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \\nspecies by building a self-sustaining city on Mars',\n",
       " 'In 2008, SpaceX’s Falcon 1 became the first privately developed \\nliquid-fuel launch vehicle to orbit the Earth.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentence Tokenization\n",
    "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
    "species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
    "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
    "# Splits at '.' \n",
    "text.split('. ') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Tokenization using Regular Expression (RegEx) </1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Founded', 'in', '2002', 'SpaceX', 's', 'mission', 'is', 'to', 'enable', 'humans', 'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 'multi', 'planet', 'species', 'by', 'building', 'a', 'self', 'sustaining', 'city', 'on', 'Mars', 'In', '2008', 'SpaceX', 's', 'Falcon', '1', 'became', 'the', 'first', 'privately', 'developed', 'liquid', 'fuel', 'launch', 'vehicle', 'to', 'orbit', 'the', 'Earth']\n"
     ]
    }
   ],
   "source": [
    "#word tokenization\n",
    "import re\n",
    "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
    "species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
    "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
    "tokens = re.findall(\"[\\w]+\", text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \\nspecies by building a self-sustaining city on, Mars',\n",
       " 'In 2008, SpaceX’s Falcon 1 became the first privately developed \\nliquid-fuel launch vehicle to orbit the Earth.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentence tokenization\n",
    "import re\n",
    "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
    "species by building a self-sustaining city on, Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
    "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
    "sentences = re.compile('[.!?] ').split(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Natural language toolkit (NLTK)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk==3.9.1 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: joblib in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from nltk==3.9.1) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from nltk==3.9.1) (2023.3.23)\n",
      "Requirement already satisfied: tqdm in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from nltk==3.9.1) (4.64.1)\n",
      "Requirement already satisfied: click in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from nltk==3.9.1) (8.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk==3.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/hoangvulinh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/hoangvulinh/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Founded',\n",
       " 'in',\n",
       " '2002',\n",
       " ',',\n",
       " 'SpaceX',\n",
       " '’',\n",
       " 's',\n",
       " 'mission',\n",
       " 'is',\n",
       " 'to',\n",
       " 'enable',\n",
       " 'humans',\n",
       " 'to',\n",
       " 'become',\n",
       " 'a',\n",
       " 'spacefaring',\n",
       " 'civilization',\n",
       " 'and',\n",
       " 'a',\n",
       " 'multi-planet',\n",
       " 'species',\n",
       " 'by',\n",
       " 'building',\n",
       " 'a',\n",
       " 'self-sustaining',\n",
       " 'city',\n",
       " 'on',\n",
       " 'Mars',\n",
       " '.',\n",
       " 'In',\n",
       " '2008',\n",
       " ',',\n",
       " 'SpaceX',\n",
       " '’',\n",
       " 's',\n",
       " 'Falcon',\n",
       " '1',\n",
       " 'became',\n",
       " 'the',\n",
       " 'first',\n",
       " 'privately',\n",
       " 'developed',\n",
       " 'liquid-fuel',\n",
       " 'launch',\n",
       " 'vehicle',\n",
       " 'to',\n",
       " 'orbit',\n",
       " 'the',\n",
       " 'Earth',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
    "species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
    "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
    "word_tokenize(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \\nspecies by building a self-sustaining city on Mars.',\n",
       " 'In 2008, SpaceX’s Falcon 1 became the first privately developed \\nliquid-fuel launch vehicle to orbit the Earth.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentence Tokenization\n",
    "from nltk.tokenize import sent_tokenize\n",
    "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
    "species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
    "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Tokenization using the spaCy library </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.3-cp310-cp310-macosx_11_0_arm64.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting thinc<8.4.0,>=8.3.0\n",
      "  Downloading thinc-8.3.3-cp310-cp310-macosx_11_0_arm64.whl (779 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.4/779.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.10-cp310-cp310-macosx_11_0_arm64.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from spacy) (1.26.4)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from spacy) (2.8.2)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hoangvulinh/.local/lib/python3.10/site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: setuptools in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from spacy) (65.5.0)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.9-cp310-cp310-macosx_11_0_arm64.whl (127 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.8/127.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.5.0-cp310-cp310-macosx_11_0_arm64.whl (634 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m634.4/634.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting weasel<0.5.0,>=0.1.0\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from spacy) (4.64.1)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.11-cp310-cp310-macosx_11_0_arm64.whl (26 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0\n",
      "  Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Collecting language-data>=1.2\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.19)\n",
      "Collecting blis<1.2.0,>=1.1.0\n",
      "  Downloading blis-1.1.0-cp310-cp310-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting confection<1.0.0,>=0.0.1\n",
      "  Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Collecting shellingham>=1.3.0\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.3)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cloudpathlib<1.0.0,>=0.7.0\n",
      "  Using cached cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from jinja2->spacy) (2.1.2)\n",
      "Collecting marisa-trie>=1.1.0\n",
      "  Downloading marisa_trie-1.2.1-cp310-cp310-macosx_11_0_arm64.whl (174 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.7/174.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/hoangvulinh/.local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
      "Requirement already satisfied: wrapt in /Users/hoangvulinh/.local/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.15.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, shellingham, murmurhash, mdurl, marisa-trie, cloudpathlib, catalogue, blis, srsly, preshed, markdown-it-py, language-data, rich, langcodes, confection, typer, thinc, weasel, spacy\n",
      "Successfully installed blis-1.1.0 catalogue-2.0.10 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.10 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.11 preshed-3.0.9 rich-13.9.4 shellingham-1.5.4 smart-open-7.1.0 spacy-3.8.3 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.0 thinc-8.3.3 typer-0.15.1 wasabi-1.1.3 weasel-0.4.1\n",
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "#load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Founded',\n",
       " 'in',\n",
       " '2002',\n",
       " ',',\n",
       " 'SpaceX',\n",
       " '’s',\n",
       " 'mission',\n",
       " 'is',\n",
       " 'to',\n",
       " 'enable',\n",
       " 'humans',\n",
       " 'to',\n",
       " 'become',\n",
       " 'a',\n",
       " 'spacefaring',\n",
       " 'civilization',\n",
       " 'and',\n",
       " 'a',\n",
       " 'multi',\n",
       " '-',\n",
       " 'planet',\n",
       " '\\n',\n",
       " 'species',\n",
       " 'by',\n",
       " 'building',\n",
       " 'a',\n",
       " 'self',\n",
       " '-',\n",
       " 'sustaining',\n",
       " 'city',\n",
       " 'on',\n",
       " 'Mars',\n",
       " '.',\n",
       " 'In',\n",
       " '2008',\n",
       " ',',\n",
       " 'SpaceX',\n",
       " '’s',\n",
       " 'Falcon',\n",
       " '1',\n",
       " 'became',\n",
       " 'the',\n",
       " 'first',\n",
       " 'privately',\n",
       " 'developed',\n",
       " '\\n',\n",
       " 'liquid',\n",
       " '-',\n",
       " 'fuel',\n",
       " 'launch',\n",
       " 'vehicle',\n",
       " 'to',\n",
       " 'orbit',\n",
       " 'the',\n",
       " 'Earth',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
    "species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
    "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
    "# \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "my_doc = nlp(text)\n",
    "\n",
    "#Create list of word tokens\n",
    "token_list = []\n",
    "for token in my_doc:\n",
    "    token_list.append(token.text)\n",
    "\n",
    "token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \\nspecies by building a self-sustaining city on Mars.',\n",
       " 'In 2008, SpaceX’s Falcon 1 became the first privately developed \\nliquid-fuel launch vehicle to orbit the Earth.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentence Tokenization\n",
    "from spacy.lang.en import English\n",
    "#Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = English()\n",
    "# #Create the pipeline 'sentencizer' component\n",
    "\n",
    "# sbd = nlp.create_pipe('sentencizer')\n",
    "\n",
    "#Add the component to the pipeline\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
    "species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
    "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
    "\n",
    "#\"nlp\" Object is used to create documents with linguistic annotations.\n",
    "\n",
    "doc = nlp(text)\n",
    "#create list of sentence tokens\n",
    "sents_list = []\n",
    "for sent in doc.sents:\n",
    "    sents_list.append(sent.text)\n",
    "\n",
    "sents_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Tokenization using Keras </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Keras\n",
      "  Downloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting optree\n",
      "  Downloading optree-0.13.1-cp310-cp310-macosx_11_0_arm64.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m377.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from Keras) (1.26.4)\n",
      "Collecting h5py\n",
      "  Downloading h5py-3.12.1-cp310-cp310-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m347.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m823.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ml-dtypes\n",
      "  Downloading ml_dtypes-0.5.1-cp310-cp310-macosx_10_9_universal2.whl (671 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.5/671.5 kB\u001b[0m \u001b[31m886.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/hoangvulinh/.local/lib/python3.10/site-packages (from Keras) (23.0)\n",
      "Collecting namex\n",
      "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: rich in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from Keras) (13.9.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from optree->Keras) (4.12.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/hoangvulinh/.local/lib/python3.10/site-packages (from rich->Keras) (2.16.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from rich->Keras) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->Keras) (0.1.2)\n",
      "Installing collected packages: namex, optree, ml-dtypes, h5py, absl-py, Keras\n",
      "Successfully installed Keras-3.8.0 absl-py-2.1.0 h5py-3.12.1 ml-dtypes-0.5.1 namex-0.0.8 optree-0.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/hoangvulinh/.local/lib/python3.10/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: packaging in /Users/hoangvulinh/.local/lib/python3.10/site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (24.12.23)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (1.66.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (5.27.4)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: setuptools in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: namex in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: rich in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.19)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/hoangvulinh/.local/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['founded', 'in', '2002', 'spacex’s', 'mission', 'is', 'to', 'enable', 'humans', 'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 'multi', 'planet', 'species', 'by', 'building', 'a', 'self', 'sustaining', 'city', 'on', 'mars', 'in', '2008', 'spacex’s', 'falcon', '1', 'became', 'the', 'first', 'privately', 'developed', 'liquid', 'fuel', 'launch', 'vehicle', 'to', 'orbit', 'the', 'earth']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "# Define text\n",
    "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization \n",
    "and a multi-planet species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 \n",
    "became the first privately developed liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
    "\n",
    "# Tokenize text\n",
    "tokens = text_to_word_sequence(text)\n",
    "\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Tokenization using Gensim </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp310-cp310-macosx_11_0_arm64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0\n",
      "  Downloading scipy-1.13.1-cp310-cp310-macosx_12_0_arm64.whl (30.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.3/30.3 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.18.5 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in /Users/hoangvulinh/.local/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim) (1.15.0)\n",
      "Installing collected packages: scipy, gensim\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.0\n",
      "    Uninstalling scipy-1.15.0:\n",
      "      Successfully uninstalled scipy-1.15.0\n",
      "Successfully installed gensim-4.3.3 scipy-1.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Founded',\n",
       " 'in',\n",
       " 'SpaceX',\n",
       " 's',\n",
       " 'mission',\n",
       " 'is',\n",
       " 'to',\n",
       " 'enable',\n",
       " 'humans',\n",
       " 'to',\n",
       " 'become',\n",
       " 'a',\n",
       " 'spacefaring',\n",
       " 'civilization',\n",
       " 'and',\n",
       " 'a',\n",
       " 'multi',\n",
       " 'planet',\n",
       " 'species',\n",
       " 'by',\n",
       " 'building',\n",
       " 'a',\n",
       " 'self',\n",
       " 'sustaining',\n",
       " 'city',\n",
       " 'on',\n",
       " 'Mars',\n",
       " 'In',\n",
       " 'SpaceX',\n",
       " 's',\n",
       " 'Falcon',\n",
       " 'became',\n",
       " 'the',\n",
       " 'first',\n",
       " 'privately',\n",
       " 'developed',\n",
       " 'liquid',\n",
       " 'fuel',\n",
       " 'launch',\n",
       " 'vehicle',\n",
       " 'to',\n",
       " 'orbit',\n",
       " 'the',\n",
       " 'Earth']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word Tokenization\n",
    "from gensim.utils import tokenize\n",
    "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
    "species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
    "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
    "list(tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet ',\n",
       " 'species by building a self-sustaining city on Mars.',\n",
       " 'In 2008, SpaceX’s Falcon 1 became the first privately developed ',\n",
       " 'liquid-fuel launch vehicle to orbit the Earth.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentence Tokenization\n",
    "from gensim.summarization.textcleaner import split_sentences\n",
    "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
    "species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
    "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
    "result = split_sentences(text)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==3.4.0\n",
      "  Downloading gensim-3.4.0.tar.gz (22.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from gensim==3.4.0) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from gensim==3.4.0) (1.13.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from gensim==3.4.0) (1.16.0)\n",
      "Requirement already satisfied: smart_open>=1.2.1 in /Users/hoangvulinh/miniforge3/lib/python3.10/site-packages (from gensim==3.4.0) (7.1.0)\n",
      "Requirement already satisfied: wrapt in /Users/hoangvulinh/.local/lib/python3.10/site-packages (from smart_open>=1.2.1->gensim==3.4.0) (1.15.0)\n",
      "Building wheels for collected packages: gensim\n",
      "  Building wheel for gensim (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gensim: filename=gensim-3.4.0-cp310-cp310-macosx_11_0_arm64.whl size=22417427 sha256=e7b6c91661ce63274d0e52c98bb0a290f3617ede20c3bb87d1b6815181b4962e\n",
      "  Stored in directory: /Users/hoangvulinh/Library/Caches/pip/wheels/16/56/72/c8bcd3a4035940aebd17219a71ba4d53e28da1323103b05614\n",
      "Successfully built gensim\n",
      "Installing collected packages: gensim\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 3.8.2\n",
      "    Uninstalling gensim-3.8.2:\n",
      "      Successfully uninstalled gensim-3.8.2\n",
      "Successfully installed gensim-3.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim==3.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
